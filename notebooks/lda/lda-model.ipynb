{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we demonstrate the use of **LDA (Latent Dirichlet Allocation)** generative statistical model for Information Retrieval technique to make trace link recovery between Use Cases and Bug Reports.\n",
    "\n",
    "We model our study as follows:\n",
    "\n",
    "* Each bug report title, summary and description compose a single query.\n",
    "* We use each use case content as an entire document that must be returned to the query made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from dit.divergences import jensen_shannon_divergence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, pairwise_distances, pairwise\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "import datetime\n",
    "import pprint\n",
    "from enum import Enum\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleLoader:\n",
    "    def __init__(self, rows_names, columns_names):\n",
    "        self.oracle = None\n",
    "        self._columns_names = columns_names\n",
    "        self._rows_names = rows_names\n",
    "    \n",
    "    def load(self):\n",
    "        self.oracle = pd.DataFrame(columns=list(self._columns_names), \n",
    "                                   data=np.zeros(shape=(len(self._rows_names), len(self._columns_names)), \n",
    "                                                 dtype='int64'))\n",
    "        self.oracle.insert(0, 'artf_name', list(self._rows_names))\n",
    "        \n",
    "        for index, row in trace_df.iterrows():\n",
    "            idx = self.oracle[self.oracle.artf_name == row['trg_artf']].index\n",
    "            self.oracle.at[idx, row['src_artf']] = row['link']\n",
    "\n",
    "        self.oracle.set_index('artf_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_df = pd.read_csv('../../data/jEdit/jEditDataset/oracle/output/trace_matrix.csv')\n",
    "artfs_desc_df = pd.read_csv('../../data/jEdit/jEditDataset/oracle/output/artifacts_descriptions.csv', sep=\"|\")\n",
    "\n",
    "use_cases_df = artfs_desc_df[artfs_desc_df.artf_description.str.contains('Use Case ID')]\n",
    "bug_reports_df = artfs_desc_df[artfs_desc_df.artf_description.str.contains('Bug Number')]\n",
    "\n",
    "corpus = use_cases_df.artf_description\n",
    "query = bug_reports_df.artf_description\n",
    "\n",
    "use_cases_names = use_cases_df.artf_name\n",
    "bug_reports_names = bug_reports_df.artf_name\n",
    "\n",
    "orc = OracleLoader(use_cases_names, bug_reports_names)\n",
    "orc.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA_Model_Hyperp(Enum):\n",
    "    NAME = 'lda__name'\n",
    "    SIM_MEASURE_MIN_THRESHOLD = 'lda__sim_measure_min_threshold'\n",
    "    VECTORIZER = 'lda__vectorizer'\n",
    "    VECTORIZER_STOP_WORDS = 'lda__vectorizer__stop_words'\n",
    "    VECTORIZER_TOKENIZER = 'lda__vectorizer__tokenizer'\n",
    "    VECTORIZER_USE_IDF = 'lda__vectorizer__use_idf'\n",
    "    VECTORIZER_SMOOTH_IDF = 'lda__vectorizer__smooth_idf'\n",
    "    VECTORIZER_NGRAM_RANGE = 'lda__vectorizer__ngram_range'\n",
    "    LDA_MODEL = 'lda__lda_model'\n",
    "    LDA_MODEL_N_COMPONENTS = 'lda__lda_model__n_components'\n",
    "    LDA_MODEL_RANDOM_STATE = 'lda__lda_model__random_state'\n",
    "    TOKENIZER = 'lda__tokenizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Others stemmers are not relevant for our analysis:\n",
    " . RSLP Stemmer: portuguese language\n",
    " . ISRIS Stemmer: returns Arabic root for the given token \n",
    " . Regexp Stemmer: uses regulax expressions to identify morphological affixes\n",
    " \n",
    "Relevant Stemmers/Lemmatizers are implemented below. \n",
    "\"\"\"\n",
    "\n",
    "class GenericTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stopwords = nltk.corpus.stopwords.words('english')\n",
    "    def __call__(self, doc):\n",
    "        tokens = [self.stemmer.stem(token) for token in word_tokenize(doc)]\n",
    "        return [unicode(token.lower(), 'utf-8') for token in tokens if token.isalpha() and token not in self.stopwords]\n",
    "        \n",
    "class WordNetBased_LemmaTokenizer(GenericTokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        tokens = [self.wnl.lemmatize(token) for token in word_tokenize(doc)]\n",
    "        return [token.lower() for token in tokens if token.isalpha() and token not in self.stopwords]\n",
    "\n",
    "class LancasterStemmerBased_Tokenizer(GenericTokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stemmer = LancasterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return super().__call__(doc)\n",
    "\n",
    "class PorterStemmerBased_Tokenizer(GenericTokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stemmer = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return super().__call__(doc)\n",
    "    \n",
    "class SnowballStemmerBased_Tokenizer(GenericTokenizer):    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stemmer = SnowballStemmer('english')    \n",
    "    def __call__(self, doc):\n",
    "        return super().__call__(doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jensen-shannon divergence\n",
    "\n",
    "from scipy.stats import entropy\n",
    "def jsd(p, q):\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "   # normalize\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "    m = (p + q) / 2\n",
    "    return (entropy(p, m) + entropy(q, m)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params_dict = {\n",
    "    'lda__name' : 'LDA',\n",
    "    'lda__sim_measure_min_threshold' : ('cosine',.9),\n",
    "    'lda__vectorizer' : TfidfVectorizer(),\n",
    "    'lda__vectorizer__stop_words' : 'english',\n",
    "    'lda__vectorizer__tokenizer' : Tokenizer(),\n",
    "    'lda__vectorizer__use_idf' : True,          # optional if type(Vectorizer) == TfidfVectorizer\n",
    "    'lda__vectorizer__smooth_idf' : True,       # optional if type(Vectorizer) == TfidfVectorizer\n",
    "    'lda__vectorizer__ngram_range' : (1,2),\n",
    "    'lda__lda_model' : TruncatedSVD(),\n",
    "    'lda__lda_model__n_components' : 5\n",
    "}\n",
    "\"\"\"\n",
    "class LDA:\n",
    "    def __init__(self, **kwargs):\n",
    "        self._corpus_matrix = None\n",
    "        self._query_vector = None\n",
    "        \n",
    "        self.name = None\n",
    "        self.sim_measure_min_threshold = None\n",
    "        self.trace_links_df = None\n",
    "        self.vectorizer = None\n",
    "        self.lda_model = LatentDirichletAllocation()\n",
    "        \n",
    "        self.set_name(**kwargs)\n",
    "        self.set_sim_measure_min_threshold(**kwargs)\n",
    "        self.set_vectorizer(**kwargs)\n",
    "        self.set_lda_model(**kwargs)\n",
    "    \n",
    "    def set_name(self, **kwargs):\n",
    "        self.name = 'LDA' if LDA_Model_Hyperp.NAME.value not in kwargs.keys() else kwargs[LDA_Model_Hyperp.NAME.value]\n",
    "    \n",
    "    def set_sim_measure_min_threshold(self, **kwargs):\n",
    "        self.sim_measure_min_threshold = ('jsd', .80) if LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value not in kwargs.keys() else kwargs[LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value]\n",
    "    \n",
    "    def set_vectorizer(self, **kwargs):\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                             use_idf=True, \n",
    "                                             smooth_idf=True) if LDA_Model_Hyperp.VECTORIZER.value not in kwargs.keys() else kwargs[LDA_Model_Hyperp.VECTORIZER.value]\n",
    "        \n",
    "        vec_params = {key.split('__')[2]:kwargs[key] for key,val in kwargs.items() if '__vectorizer__' in key}\n",
    "        self.vectorizer.set_params(**vec_params)\n",
    "    \n",
    "    def set_lda_model(self, **kwargs):      \n",
    "        lda_model_params = {key.split('__')[2]:kwargs[key] for key,val in kwargs.items() if '__lda_model__' in key}\n",
    "        self.lda_model.set_params(**lda_model_params)\n",
    "    \n",
    "    def recover_links(self, corpus, query, use_cases_names, bug_reports_names):\n",
    "        self._corpus_matrix = self.vectorizer.fit_transform(corpus)\n",
    "        self._query_vector = self.vectorizer.transform(query)\n",
    "        \n",
    "        out_1 = self.lda_model.fit_transform(self._corpus_matrix)\n",
    "        out_2 = self.lda_model.transform(self._query_vector)\n",
    "        \n",
    "        # D 14 x 10\n",
    "        self._sim_matrix = pairwise_distances(X=out_1, Y=out_2, metric=jensen_shannon_divergence)\n",
    "            \n",
    "        self.trace_links_df = pd.DataFrame(index = use_cases_names, \n",
    "                                           columns = bug_reports_names,\n",
    "                                           data = self._sim_matrix)\n",
    "        \n",
    "        for col in self.trace_links_df.columns:\n",
    "            self.trace_links_df[col] = [1 if x >= self.sim_measure_min_threshold[1] else 0 for x in self.trace_links_df[col]]\n",
    "\n",
    "\n",
    "    def model_setup(self):\n",
    "        return {\"Setup\" : \n",
    "                  [\n",
    "                      {\"Similarity Measure and Minimum Threshold\" : self.sim_measure_min_threshold},\n",
    "                      {\"LDA Model\" : self.lda_model.get_params()},\n",
    "                      {\"Vectorizer\" : self.vectorizer.get_params()},\n",
    "                      {\"Vectorizer Type\" : type(self.vectorizer)}\n",
    "                  ]\n",
    "               }\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_query_vector(self):\n",
    "        return self._query_vector\n",
    "    \n",
    "    def get_corpus_matrix(self):\n",
    "        return self._corpus_matrix\n",
    "    \n",
    "    def get_sim_measure_min_threshold(self):\n",
    "        return self.sim_measure_min_threshold\n",
    "    \n",
    "    def get_trace_links_df(self):\n",
    "        return self.trace_links_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import dit\n",
    "\n",
    "\"\"\"\n",
    "params_dict = {\n",
    "    'lda__name' : 'LDA',\n",
    "    'lda__sim_measure_min_threshold' : ('cosine',.9),\n",
    "    'lda__vectorizer' : TfidfVectorizer(),\n",
    "    'lda__vectorizer__stop_words' : 'english',\n",
    "    'lda__vectorizer__tokenizer' : Tokenizer(),\n",
    "    'lda__vectorizer__use_idf' : True,          # optional if type(Vectorizer) == TfidfVectorizer\n",
    "    'lda__vectorizer__smooth_idf' : True,       # optional if type(Vectorizer) == TfidfVectorizer\n",
    "    'lda__vectorizer__ngram_range' : (1,2),\n",
    "    'lda__lda_model' : TruncatedSVD(),\n",
    "    'lda__lda_model__n_components' : 5,\n",
    "    'lda__tokenizer' : WordNetBased_LemmaTokenizer()\n",
    "}\n",
    "\"\"\"\n",
    "class OLDA:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.name = None\n",
    "        self.sim_measure_min_threshold = None\n",
    "        self.trace_links_df = None\n",
    "        self.tokenizer = None\n",
    "        \n",
    "        self.set_basic_params(**kwargs)\n",
    "    \n",
    "    def set_basic_params(self, **kwargs):\n",
    "        self.name = 'LDA' if LDA_Model_Hyperp.NAME.value not in kwargs.keys() else kwargs[LDA_Model_Hyperp.NAME.value]\n",
    "        self.sim_measure_min_threshold = ('jsd', 3) if LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value not in kwargs.keys() else kwargs[LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value]\n",
    "        self.tokenizer = WordNetBased_LemmaTokenizer() if LDA_Model_Hyperp.TOKENIZER.value not in kwargs.keys() else kwargs[LDA_Model_Hyperp.TOKENIZER.value]\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def recover_links(self, corpus, query, use_cases_names, bug_reports_names):                \n",
    "        corpus_tokens = [self.tokenizer.__call__(doc) for doc in corpus]\n",
    "        dictionary = Dictionary(corpus_tokens)\n",
    "        print('dictionary: {}'.format(dictionary))\n",
    "                      \n",
    "        corpus_bow = [dictionary.doc2bow(doc) for doc in corpus_tokens]\n",
    "        \n",
    "        ldamodel = LdaModel(corpus_bow, num_topics=4, id2word=dictionary, passes=2)\n",
    "        \n",
    "        topics = ldamodel.print_topics(num_words=10)\n",
    "        for topic in topics:\n",
    "            print('topic: {}'.format(topic))\n",
    "        \n",
    "        queries_tokens = [self.tokenizer.__call__(doc) for doc in query]\n",
    "        queries_bow = [dictionary.doc2bow(doc) for doc in queries_tokens]\n",
    "        \n",
    "        self.trace_links_df = pd.DataFrame(index = use_cases_names, \n",
    "                                           columns = bug_reports_names,\n",
    "                                           data=np.zeros(shape=(len(use_cases_names), len(bug_reports_names)), dtype='float64'))\n",
    "        \n",
    "        doc_topic_dist = np.array([[tup[1] for tup in lst] for lst in ldamodel[corpus_bow]])\n",
    "        print(\"doc_topic_dist.shape: {}\".format(doc_topic_dist.shape))\n",
    "        print(\"doc_topic_dist: {}\".format(doc_topic_dist))\n",
    "        \n",
    "        queries_topic_dist = np.array([[tup[1] for tup in lst] for lst in ldamodel.get_document_topics(bow=query) for query in queries_bow])\n",
    "        print(queries_topic_dist)\n",
    "        \n",
    "        for lst in ldamodel[corpus_bow]:\n",
    "            print(\"lst: {}\".format(lst))\n",
    "        \n",
    "        for bug_id, bug_tokens in zip(bug_reports_names, queries_bow):\n",
    "            #print('bug_tokens: {}'.format(bug_tokens))\n",
    "            print(\"ldamodel[bug_tokens]: {}\".format(ldamodel[bug_tokens]))\n",
    "            print(\"len(ldamodel[bug_tokens]): {}\".format(len(ldamodel.get_document_topics(bug_tokens))))\n",
    "            topics_distrib_bug = dit.ScalarDistribution([x[1] for x in ldamodel.get_document_topics(bug_tokens)])\n",
    "            #print('topics_distrib_bug: {}'.format(topics_distrib_bug))\n",
    "            for uc_id, uc_bow in zip(use_cases_names, corpus_bow):\n",
    "                print('ldamodel.get_document_topics(uc_bow): {}'.format(ldamodel[uc_bow]))\n",
    "                topics_distrib_uc = dit.ScalarDistribution([x[1] for x in ldamodel[uc_bow]])\n",
    "                #print('topics_distrib_uc: {}'.format(topics_distrib_uc))\n",
    "                self.trace_links_df.at[uc_id, bug_id] = jensen_shannon_divergence(dists=[topics_distrib_bug, topics_distrib_uc], weights=None)\n",
    "        \n",
    "        for col in self.trace_links_df.columns:\n",
    "            nlargest_df = self.trace_links_df.nlargest(n = self.sim_measure_min_threshold[1], columns=col, keep='first')    \n",
    "            self.trace_links_df[col] = [1 if x in nlargest_df[col].tolist() else 0 for x in self.trace_links_df[col]]\n",
    "        \n",
    "\n",
    "    def model_setup(self):\n",
    "        return {\"Setup\" : \n",
    "                  [\n",
    "                      {\"Name\" : self.name},\n",
    "                      {\"Similarity Measure and Minimum Threshold\" : self.sim_measure_min_threshold},\n",
    "                      {\"Tokenizer\" : type(self.tokenizer)}\n",
    "                  ]\n",
    "               }\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_sim_measure_min_threshold(self):\n",
    "        return self.sim_measure_min_threshold\n",
    "    \n",
    "    def get_trace_links_df(self):\n",
    "        return self.trace_links_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary: Dictionary(135 unique tokens: ['area', 'asks', 'basic', 'beginning', 'box']...)\n",
      "topic: (0, '0.078*\"user\" + 0.066*\"system\" + 0.049*\"text\" + 0.044*\"button\" + 0.042*\"click\" + 0.029*\"display\" + 0.027*\"window\" + 0.021*\"search\" + 0.021*\"found\" + 0.020*\"new\"')\n",
      "topic: (1, '0.076*\"system\" + 0.071*\"file\" + 0.071*\"user\" + 0.037*\"display\" + 0.033*\"text\" + 0.030*\"click\" + 0.029*\"name\" + 0.028*\"button\" + 0.026*\"view\" + 0.024*\"main\"')\n",
      "topic: (2, '0.080*\"user\" + 0.067*\"system\" + 0.044*\"display\" + 0.039*\"click\" + 0.033*\"button\" + 0.032*\"help\" + 0.024*\"case\" + 0.023*\"use\" + 0.022*\"shortcut\" + 0.022*\"new\"')\n",
      "topic: (3, '0.056*\"user\" + 0.053*\"system\" + 0.035*\"display\" + 0.035*\"bracket\" + 0.030*\"click\" + 0.029*\"option\" + 0.026*\"button\" + 0.024*\"matching\" + 0.022*\"caret\" + 0.020*\"next\"')\n",
      "doc_topic_dist.shape: (10, 1)\n",
      "doc_topic_dist: [[0.994363  ]\n",
      " [0.99168056]\n",
      " [0.98944175]\n",
      " [0.9881525 ]\n",
      " [0.99145645]\n",
      " [0.9933909 ]\n",
      " [0.98916507]\n",
      " [0.98538727]\n",
      " [0.9925444 ]\n",
      " [0.9901847 ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-f80ec0614917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cases_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbug_reports_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-b90a19385123>\u001b[0m in \u001b[0;36mrecover_links\u001b[0;34m(self, corpus, query, use_cases_names, bug_reports_names)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"doc_topic_dist: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mqueries_topic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries_bow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m   1308\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalize distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0;31m# make sure the term IDs are ints, otherwise np will get upset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0;31m# make sure the term IDs are ints, otherwise np will get upset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model = OLDA()\n",
    "model.recover_links(corpus, query, use_cases_names, bug_reports_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, oracle, model):\n",
    "        self.model = model\n",
    "        self.oracle = oracle\n",
    "        self.recovered_links = model.trace_links_df\n",
    "        \n",
    "        self.eval_df = pd.DataFrame(columns=['precision','recall','fscore','support'])\n",
    "        self.mean_precision = -1\n",
    "        self.mean_recall = -1\n",
    "        self.mean_fscore = -1\n",
    "    \n",
    "    def evaluate_model(self, verbose=False, file=None):\n",
    "        y_true = csr_matrix(self.oracle.values, dtype=int)\n",
    "        y_pred = csr_matrix(self.recovered_links.values, dtype=int)\n",
    "        \n",
    "        p, r, f, sp = precision_recall_fscore_support(y_true, y_pred)\n",
    "\n",
    "        i = 0\n",
    "        for idx, row in self.oracle.iteritems():\n",
    "            self.eval_df.at[idx, 'precision'] = p[i]\n",
    "            self.eval_df.at[idx, 'recall'] = r[i]\n",
    "            self.eval_df.at[idx, 'fscore'] = f[i]\n",
    "            self.eval_df.at[idx, 'support'] = sp[i]\n",
    "            i += 1\n",
    "        \n",
    "        self.mean_precision = self.eval_df.precision.mean()\n",
    "        self.mean_recall = self.eval_df.recall.mean()\n",
    "        self.mean_fscore = self.eval_df.fscore.mean()\n",
    "        \n",
    "        if verbose:\n",
    "            self.print_report(file)\n",
    "    \n",
    "    def print_report(self, file=None):\n",
    "        dic = self.model.model_setup()\n",
    "        dic['Measures'] = {}\n",
    "        dic['Measures']['Mean Precision of {}'.format(self.model.get_name())] = self.get_mean_precision()\n",
    "        dic['Measures']['Mean Recall of {}'.format(self.model.get_name())] = self.get_mean_recall()\n",
    "        dic['Measures']['Mean FScore of {}'.format(self.model.get_name())] = self.get_mean_fscore()\n",
    "        \n",
    "        if file is None:    \n",
    "            pprint.pprint(dic)\n",
    "        else:\n",
    "            file.write(pprint.pformat(dic))\n",
    "        \n",
    "    def plot_precision_vs_recall(self):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.plot(self.eval_df.recall, self.eval_df.precision, 'ro', label='Precision vs Recall')\n",
    "\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlabel('Recall')\n",
    "\n",
    "        plt.axis([0, 1.1, 0, 1.1])\n",
    "        plt.title(\"Precision vs Recall Plot - \" + self.model.get_name())\n",
    "        plt.show()\n",
    "    \n",
    "    def save_log(self):\n",
    "        print(\"\\nSaving model log...\")\n",
    "        with open('../logs/' + str(datetime.datetime.now()) + '.txt', 'a') as f:\n",
    "            evaluator.evaluate_model(verbose=True, file=f)\n",
    "        print(\"Model log saved with success!\")\n",
    "            \n",
    "    def get_mean_precision(self):\n",
    "        return self.mean_precision\n",
    "    \n",
    "    def get_mean_recall(self):\n",
    "        return self.mean_recall\n",
    "    \n",
    "    def get_mean_fscore(self):\n",
    "        return self.mean_fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Recovering Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the efficiency of the algorithm tested (LSI), we use common metrics applied in the field of IR:\n",
    "\n",
    "    * Precision\n",
    "    * Recall\n",
    "    * F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Generate Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def generate_params_comb_list(**kwargs):\n",
    "    list_params = []\n",
    "    for key, values in kwargs.items():\n",
    "        aux_list = []\n",
    "        for v in values:\n",
    "            aux_list.append((key, v))\n",
    "        list_params.append(aux_list)\n",
    "    \n",
    "    list_tuples = list(product(*list_params))\n",
    "    \n",
    "    list_dicts = []\n",
    "    for ex_tup in list_tuples:\n",
    "        dic = {}\n",
    "        for in_tup in ex_tup:\n",
    "            dic[in_tup[0]] = in_tup[1]\n",
    "        list_dicts.append(dic)\n",
    "        \n",
    "    return list_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Heatmap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(results_dict):\n",
    "    fig, ax = plt.subplots(figsize=(10,140)) \n",
    "    df = pd.DataFrame(results_dict)\n",
    "    df.set_index('model', inplace=True)       \n",
    "    ax = sns.heatmap(df, vmin=0, vmax=1, linewidths=.5, cmap=\"Greens\", annot=True, cbar=False, ax=ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Coloring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_df(df):\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    return df.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with One Combination of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "common_dictionary: Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n",
      "topic: (0, '0.081*\"user\" + 0.077*\"system\" + 0.046*\"text\" + 0.044*\"click\" + 0.043*\"button\" + 0.037*\"display\" + 0.028*\"window\" + 0.027*\"new\" + 0.023*\"file\" + 0.019*\"case\"')\n",
      "topic: (1, '0.012*\"option\" + 0.012*\"system\" + 0.011*\"display\" + 0.011*\"user\" + 0.010*\"bracket\" + 0.010*\"click\" + 0.009*\"text\" + 0.009*\"caret\" + 0.009*\"matching\" + 0.009*\"case\"')\n",
      "topic: (2, '0.009*\"user\" + 0.008*\"system\" + 0.008*\"display\" + 0.008*\"click\" + 0.008*\"shortcut\" + 0.007*\"button\" + 0.007*\"new\" + 0.007*\"use\" + 0.007*\"bracket\" + 0.007*\"case\"')\n",
      "topic: (3, '0.034*\"system\" + 0.027*\"user\" + 0.019*\"window\" + 0.018*\"text\" + 0.016*\"new\" + 0.015*\"button\" + 0.015*\"display\" + 0.015*\"click\" + 0.014*\"file\" + 0.012*\"case\"')\n",
      "topic: (4, '0.074*\"user\" + 0.068*\"system\" + 0.063*\"file\" + 0.038*\"display\" + 0.029*\"click\" + 0.029*\"main\" + 0.027*\"name\" + 0.026*\"button\" + 0.025*\"use\" + 0.024*\"case\"')\n",
      "corpus_bow_format[0]: [(5, 10), (7, 11), (12, 2), (13, 1), (14, 1), (15, 1), (16, 2), (17, 7), (18, 1), (19, 2), (20, 1), (21, 7), (22, 3), (23, 2), (24, 1), (25, 2), (26, 3), (27, 1), (28, 1), (29, 3), (30, 3), (31, 2), (32, 1), (33, 1), (34, 4), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 3), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 2), (51, 1), (52, 1), (53, 6), (54, 1), (55, 1), (56, 1), (57, 2), (58, 2), (59, 4), (60, 1), (61, 9), (62, 1), (63, 1), (64, 1), (65, 2), (66, 4), (67, 1), (68, 4), (69, 1)]\n",
      "doc_topic_dist.shape: (10,)\n",
      "doc_topic_dist: [list([0.99420923]) list([0.99152136]) list([0.9892636]) list([0.9877814])\n",
      " list([0.9911549]) list([0.84502786, 0.14991906]) list([0.98881125])\n",
      " list([0.9850646]) list([0.9923353]) list([0.9900646])]\n",
      "ldamodel[bug_tokens]: [(0, 0.45015797), (4, 0.5339888)]\n",
      "len(ldamodel[bug_tokens]): 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__str__ returned non-string (type InvalidNormalization)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidNormalization\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2960\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-ea7ac40e7abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LDA_Model_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cases_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbug_reports_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-ea5832666fb1>\u001b[0m in \u001b[0;36mrecover_links\u001b[0;34m(self, corpus, query, use_cases_names, bug_reports_names)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len(ldamodel[bug_tokens]): {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbug_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mtopics_distrib_bug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScalarDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbug_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;31m#print('topics_distrib_bug: {}'.format(topics_distrib_bug))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/dit/npscalardist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, outcomes, pmf, sample_space, base, prng, sort, sparse, trim, validate)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/dit/npscalardist.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/dit/distribution.py\u001b[0m in \u001b[0;36m_validate_normalization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/dit/validate.py\u001b[0m in \u001b[0;36mvalidate_normalization\u001b[0;34m(pmf, ops)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'TypeError'>, TypeError('__str__ returned non-string (type InvalidNormalization)',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2978\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2979\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1866\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_pdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m                         \u001b[0;31m# drop into debugger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36m_showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;34mu'traceback'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;34mu'ename'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0;34mu'evalue'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpy3compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         }\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/ipython_genutils/py3compat.py\u001b[0m in \u001b[0;36msafe_unicode\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __str__ returned non-string (type InvalidNormalization)"
     ]
    }
   ],
   "source": [
    "all_hyperparams = {\n",
    "    LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('jsd', 3)],\n",
    "    #LDA_Model_Hyperp.LDA_MODEL_N_COMPONENTS.value: [100],\n",
    "    #LDA_Model_Hyperp.LDA_MODEL_RANDOM_STATE.value : [2],\n",
    "    #LDA_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [(1,1)],\n",
    "    #LDA_Model_Hyperp.VECTORIZER.value : [CountVectorizer(stop_words='english')],\n",
    "    #LDA_Model_Hyperp.VECTORIZER_TOKENIZER.value : [WordNetBased_LemmaTokenizer()]    \n",
    "    LDA_Model_Hyperp.TOKENIZER.value : [WordNetBased_LemmaTokenizer()]\n",
    "}\n",
    "\n",
    "hyperparams = generate_params_comb_list(**all_hyperparams)\n",
    "\n",
    "print('Performing model optimizations...')\n",
    "best_precision = 0.0\n",
    "best_recall = 0.0\n",
    "best_fscore = 0.0\n",
    "best_model = None\n",
    "\n",
    "results = {'precision': [], 'recall': [], 'fscore': [], 'model': []}\n",
    "\n",
    "i = 0\n",
    "for hyperp in hyperparams:\n",
    "    current_model = OLDA(**hyperp)\n",
    "    current_model.set_name('LDA_Model_{}'.format(i))\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    \n",
    "    if best_recall <= evaluator.get_mean_recall():\n",
    "        best_recall = evaluator.get_mean_recall()\n",
    "        best_precision = evaluator.get_mean_precision()\n",
    "        best_fscore = evaluator.get_mean_fscore()\n",
    "        best_model = current_model\n",
    "    \n",
    "    results['precision'].append(evaluator.get_mean_precision())\n",
    "    results['recall'].append(evaluator.get_mean_recall())\n",
    "    results['fscore'].append(evaluator.get_mean_fscore())\n",
    "    results['model'].append(current_model.get_name())\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"------------ Report -------------------\\n\")\n",
    "print(\"Total of Analyzed Hyperparameters Combinations: {}\".format(len(hyperparams)))\n",
    "\n",
    "print(\"\\nBest Model and Hyperparameters Found: {}\\n\".format(best_model.get_name()))            \n",
    "evaluator = ModelEvaluator(orc.oracle, best_model)\n",
    "evaluator.evaluate_model(verbose=True)\n",
    "\n",
    "#print(\"\\nPlot Precision vs Recall - Best Model\")\n",
    "#evaluator.plot_precision_vs_recall()\n",
    "\n",
    "#print(\"\\nHeatmap of All Models\")\n",
    "#plot_heatmap(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hyperparams = {\n",
    "    LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('jsd', .80), ('jsd', .85), ('jsd', .90), ('jsd', .95)],\n",
    "    LDA_Model_Hyperp.LDA_MODEL_N_COMPONENTS.value: [5,10,20,50,100],\n",
    "    LDA_Model_Hyperp.LDA_MODEL_RANDOM_STATE.value : [2],\n",
    "    LDA_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [(1,1), (1,2)],\n",
    "    LDA_Model_Hyperp.VECTORIZER.value : [TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True), \n",
    "                         CountVectorizer(stop_words='english')],\n",
    "    LDA_Model_Hyperp.VECTORIZER_TOKENIZER.value : [PorterStemmerBased_Tokenizer(), LancasterStemmerBased_Tokenizer(), \n",
    "                                                   WordNetBased_LemmaTokenizer(), SnowballStemmerBased_Tokenizer()]\n",
    "}\n",
    "\n",
    "hyperparams = generate_params_comb_list(**all_hyperparams)\n",
    "\n",
    "print('Performing model optimizations...')\n",
    "best_precision = -1\n",
    "best_recall = -1\n",
    "best_fscore = -1\n",
    "best_model = None\n",
    "\n",
    "results = {'precision': [], 'recall': [], 'fscore': [], 'model': []}\n",
    "\n",
    "i = 0\n",
    "for hyperp in hyperparams:\n",
    "    hyperp[LDA_Model_Hyperp.NAME.value] = 'LDA_Model_{}'.format(i)\n",
    "    current_model = LDA(**hyperp)\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "\n",
    "    if best_recall <= evaluator.get_mean_recall():\n",
    "        if best_precision <= evaluator.get_mean_precision():\n",
    "            best_recall = evaluator.get_mean_recall()\n",
    "            best_precision = evaluator.get_mean_precision()\n",
    "            best_fscore = evaluator.get_mean_fscore()\n",
    "            best_model = current_model\n",
    "    \n",
    "    results['precision'].append(evaluator.get_mean_precision())\n",
    "    results['recall'].append(evaluator.get_mean_recall())\n",
    "    results['fscore'].append(evaluator.get_mean_fscore())\n",
    "    results['model'].append(current_model.get_name())\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"------------ Report -------------------\\n\")\n",
    "print(\"Total of Analyzed Hyperparameters Combinations: {}\".format(len(hyperparams)))\n",
    "\n",
    "print(\"\\nBest Model and Hyperparameters Found: {}\\n\".format(best_model.get_name()))            \n",
    "evaluator = ModelEvaluator(orc.oracle, best_model)\n",
    "evaluator.evaluate_model(verbose=True)\n",
    "\n",
    "#print(\"\\nPlot Precision vs Recall - Best Model\")\n",
    "#evaluator.plot_precision_vs_recall()\n",
    "\n",
    "#print(\"\\nHeatmap of All Models\")\n",
    "#plot_heatmap(results)\n",
    "\n",
    "#evaluator.save_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_df(best_model.get_trace_links_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_df(orc.oracle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Precision and Recall vs Threshold Plot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_hyperparams_2 = {\n",
    "    LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : np.arange(0.0, 1.0, 0.05),\n",
    "    LDA_Model_Hyperp.LDA_MODEL_N_COMPONENTS.value: [best_model.lda_model.n_components],\n",
    "    LDA_Model_Hyperp.LDA_MODEL_RANDOM_STATE.value : [best_model.lda_model.random_state],\n",
    "    LDA_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [best_model.vectorizer.ngram_range],\n",
    "    LDA_Model_Hyperp.VECTORIZER.value : [best_model.vectorizer],\n",
    "    LDA_Model_Hyperp.VECTORIZER_TOKENIZER.value : [best_model.vectorizer.tokenizer]\n",
    "}\n",
    "\n",
    "hyperparams = generate_params_comb_list(**all_hyperparams)\n",
    "\n",
    "dic = {'precision':[], 'recall':[], 'threshold':[]}\n",
    "\n",
    "for hyperp in hyperparams:\n",
    "    current_model = LDA(**hyperp)\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    \n",
    "    dic['precision'].append(evaluator.get_mean_precision())\n",
    "    dic['recall'].append(evaluator.get_mean_recall())\n",
    "    dic['threshold'].append(current_model.get_sim_measure_min_threshold()[1])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "plt.plot(df['threshold'], df['precision'], 'r-')\n",
    "plt.plot(df['threshold'], df['recall'], 'b-')\n",
    "plt.xlabel('threshold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
