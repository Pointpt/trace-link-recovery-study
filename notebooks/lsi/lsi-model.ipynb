{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we demonstrate the use of **LSI (Latent Semantic Indexing)** Information Retrieval technique to make trace link recovery between Use Cases and Bug Reports.\n",
    "\n",
    "We model our study as follows:\n",
    "\n",
    "* Each bug report title, summary and description compose a single query.\n",
    "* We use each use case content as an entire document that must be returned to the query made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support, pairwise_distances, pairwise\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import nltk\n",
    "import datetime\n",
    "import pprint\n",
    "from enum import Enum\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleLoader:\n",
    "    def __init__(self, rows_names, columns_names):\n",
    "        self.oracle = None\n",
    "        self._columns_names = columns_names\n",
    "        self._rows_names = rows_names\n",
    "    \n",
    "    def load(self):\n",
    "        self.oracle = pd.DataFrame(columns=list(self._columns_names), \n",
    "                                   data=np.zeros(shape=(len(self._rows_names), len(self._columns_names)), \n",
    "                                                 dtype='int64'))\n",
    "        self.oracle.insert(0, 'artf_name', list(self._rows_names))\n",
    "        \n",
    "        for index, row in trace_df.iterrows():\n",
    "            idx = self.oracle[self.oracle.artf_name == row['trg_artf']].index\n",
    "            self.oracle.at[idx, row['src_artf']] = row['link']\n",
    "\n",
    "        self.oracle.set_index('artf_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_df = pd.read_csv('../../data/jEdit/jEditDataset/oracle/output/trace_matrix.csv')\n",
    "artfs_desc_df = pd.read_csv('../../data/jEdit/jEditDataset/oracle/output/artifacts_descriptions.csv', sep=\"|\")\n",
    "\n",
    "use_cases_df = artfs_desc_df[artfs_desc_df.artf_description.str.contains('Use Case ID')]\n",
    "bug_reports_df = artfs_desc_df[artfs_desc_df.artf_description.str.contains('Bug Number')]\n",
    "\n",
    "corpus = use_cases_df.artf_description\n",
    "query = bug_reports_df.artf_description\n",
    "\n",
    "use_cases_names = use_cases_df.artf_name\n",
    "bug_reports_names = bug_reports_df.artf_name\n",
    "\n",
    "orc = OracleLoader(use_cases_names, bug_reports_names)\n",
    "orc.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSI_Model_Hyperp(Enum):\n",
    "    NAME = 'lsi__name'\n",
    "    SIM_MEASURE_MIN_THRESHOLD = 'lsi__sim_measure_min_threshold'\n",
    "    VECTORIZER = 'lsi__vectorizer'\n",
    "    VECTORIZER_STOP_WORDS = 'lsi__vectorizer__stop_words'\n",
    "    VECTORIZER_TOKENIZER = 'lsi__vectorizer__tokenizer'\n",
    "    VECTORIZER_USE_IDF = 'lsi__vectorizer__use_idf'\n",
    "    VECTORIZER_SMOOTH_IDF = 'lsi__vectorizer__smooth_idf'\n",
    "    VECTORIZER_NGRAM_RANGE = 'lsi__vectorizer__ngram_range'\n",
    "    SVD_MODEL = 'lsi__svd_model'\n",
    "    SVD_MODEL_N_COMPONENTS = 'lsi__svd_model__n_components'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Others stemmers are not relevant for our analysis:\n",
    " . RSLP Stemmer: portuguese language\n",
    " . ISRIS Stemmer: returns Arabic root for the given token \n",
    " . Regexp Stemmer: uses regulax expressions to identify morphological affixes\n",
    " \n",
    "Relevant Stemmers/Lemmatizers are implemented below. \n",
    "\"\"\"\n",
    "\n",
    "class GenericTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stopwords = nltk.corpus.stopwords.words('english')\n",
    "    def __call__(self, doc):\n",
    "        tokens = [self.stemmer.stem(token) for token in nltk.word_tokenize(doc)]\n",
    "        #return [token.lower() for token in tokens if token.isalpha() and token not in self.stopwords and len(token) > 1]\n",
    "        return [token.lower() for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "class WordNetBased_LemmaTokenizer(GenericTokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.wnl = nltk.stem.WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        tokens = [self.wnl.lemmatize(token) for token in nltk.word_tokenize(doc)]\n",
    "        return [token.lower() for token in tokens if token.isalpha() and token not in self.stopwords]\n",
    "\n",
    "class LancasterStemmerBased_Tokenizer(GenericTokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stemmer = nltk.stem.LancasterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return super().__call__(doc)\n",
    "\n",
    "class PorterStemmerBased_Tokenizer(GenericTokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stemmer = nltk.stem.PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return super().__call__(doc)\n",
    "    \n",
    "class SnowballStemmerBased_Tokenizer(GenericTokenizer):    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stemmer = nltk.stem.SnowballStemmer('english')    \n",
    "    def __call__(self, doc):\n",
    "        return super().__call__(doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Functions / Similarity Measures Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityMeasure(Enum):\n",
    "    COSINE = 'cosine'\n",
    "    JACCARD_INDEX = 'jaccard'\n",
    "    EDIT_DISTANCE = 'edit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params_dict = {\n",
    "    'lsi__sim_measure_min_threshold' : ('cosine',.9),\n",
    "    'lsi__name' : 'LSI',\n",
    "    'lsi__vectorizer' : TfidfVectorizer(),\n",
    "    'lsi__vectorizer__stop_words' : 'english',\n",
    "    'lsi__vectorizer__tokenizer' : Tokenizer(),\n",
    "    'lsi__vectorizer__use_idf' : True,          # optional if type(Vectorizer) == TfidfVectorizer\n",
    "    'lsi__vectorizer__smooth_idf' : True,       # optional if type(Vectorizer) == TfidfVectorizer\n",
    "    'lsi__vectorizer__ngram_range' : (1,2),\n",
    "    'lsi__svd_model' : TruncatedSVD(),\n",
    "    'lsi__svd_model__n_components' : 5\n",
    "}\n",
    "\"\"\"\n",
    "class LSI:\n",
    "    def __init__(self, **kwargs):\n",
    "        self._svd_matrix = None\n",
    "        self._query_vector = None\n",
    "        \n",
    "        self.name = None\n",
    "        self.sim_measure_min_threshold = None\n",
    "        self.trace_links_df = None\n",
    "        self.vectorizer = None\n",
    "        self.svd_model = None\n",
    "        \n",
    "        self.set_basic_params(**kwargs)\n",
    "        self.set_vectorizer(**kwargs)\n",
    "        self.set_svd_model(**kwargs)\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def set_basic_params(self, **kwargs):\n",
    "        self.name = 'LSI' if LSI_Model_Hyperp.NAME.value not in kwargs.keys() else kwargs[LSI_Model_Hyperp.NAME.value]\n",
    "        self.sim_measure_min_threshold = (SimilarityMeasure.COSINE.value,.80) if LSI_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value not in kwargs.keys() else kwargs[LSI_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value]\n",
    "    \n",
    "    def set_vectorizer(self, **kwargs):\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                             use_idf=True, \n",
    "                                             smooth_idf=True) if LSI_Model_Hyperp.VECTORIZER.value not in kwargs.keys() else kwargs[LSI_Model_Hyperp.VECTORIZER.value]\n",
    "        \n",
    "        vec_params = {key.split('__')[2]:kwargs[key] for key,val in kwargs.items() if '__vectorizer__' in key}\n",
    "        self.vectorizer.set_params(**vec_params)\n",
    "    \n",
    "    def set_svd_model(self, **kwargs):\n",
    "        self.svd_model = TruncatedSVD(n_components = 100, \n",
    "                                         algorithm = 'randomized',\n",
    "                                         n_iter = 10, \n",
    "                                         random_state = 42) if LSI_Model_Hyperp.SVD_MODEL.value not in kwargs.keys() else kwargs[LSI_Model_Hyperp.SVD_MODEL.value]\n",
    "        \n",
    "        svd_model_params = {key.split('__')[2]:kwargs[key] for key,val in kwargs.items() if '__svd_model__' in key}\n",
    "        self.svd_model.set_params(**svd_model_params)\n",
    "    \n",
    "    def recover_links(self, corpus, query, use_cases_names, bug_reports_names):\n",
    "        metric = self.sim_measure_min_threshold[0]\n",
    "        \n",
    "        if metric == SimilarityMeasure.COSINE.value:\n",
    "            return self._recover_links_cosine(corpus, query, use_cases_names, bug_reports_names)\n",
    "        \n",
    "        elif metric == SimilarityMeasure.JACCARD_INDEX.value:\n",
    "            return self._recover_links_jaccard(corpus, query, use_cases_names, bug_reports_names)\n",
    "        \n",
    "        elif metric == SimilarityMeasure.EDIT_DISTANCE.value:\n",
    "            return self._recover_links_edit(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    def _recover_links_cosine(self, corpus, query, use_cases_names, bug_reports_names):\n",
    "        svd_transformer = Pipeline([('vec', self.vectorizer), \n",
    "                            ('svd', self.svd_model)])\n",
    "\n",
    "        self._svd_matrix = svd_transformer.fit_transform(corpus)\n",
    "        self._query_vector = svd_transformer.transform(query)\n",
    "        self._sim_matrix = pairwise.cosine_similarity(X=self._svd_matrix, Y=self._query_vector)\n",
    "\n",
    "        self.trace_links_df = pd.DataFrame(index = use_cases_names, \n",
    "                                       columns = bug_reports_names,\n",
    "                                       data = self._sim_matrix)\n",
    "\n",
    "        for col in self.trace_links_df.columns:\n",
    "            self.trace_links_df[col] = [1 if x >= self.sim_measure_min_threshold[1] else 0 for x in self.trace_links_df[col]]\n",
    "    \n",
    "    def _recover_links_jaccard(self, corpus, query, use_cases_names, bug_reports_names):\n",
    "        tokenizer = self.vectorizer.tokenizer\n",
    "                \n",
    "        corpus_tokens = [tokenizer.__call__(doc) for doc in corpus]        \n",
    "        query_tokens = [tokenizer.__call__(doc) for doc in query]\n",
    "        \n",
    "        self._sim_matrix = pd.DataFrame(index = use_cases_names, \n",
    "                                       columns = bug_reports_names,\n",
    "                                       data = np.zeros(shape=(len(use_cases_names), len(bug_reports_names)), dtype='int64'))\n",
    "        \n",
    "        self.trace_links_df = pd.DataFrame(index = use_cases_names, \n",
    "                                       columns = bug_reports_names,\n",
    "                                       data = self._sim_matrix)\n",
    "        \n",
    "        for br_id, doc_query_tset in zip(bug_reports_names, query_tokens):\n",
    "            for uc_id, doc_corpus_tset in zip(use_cases_names, corpus_tokens):\n",
    "                self._sim_matrix.at[uc_id, br_id] = nltk.jaccard_distance(set(doc_corpus_tset), set(doc_query_tset))\n",
    "\n",
    "        for col in self.trace_links_df.columns:\n",
    "            self.trace_links_df[col] = [1 if x >= self.sim_measure_min_threshold[1] else 0 for x in self.trace_links_df[col]]\n",
    "    \n",
    "    def _recover_links_edit(self, corpus, query, use_cases_names, bug_reports_names):\n",
    "        self._sim_matrix = pd.DataFrame(index = use_cases_names, \n",
    "                                       columns = bug_reports_names,\n",
    "                                       data = np.zeros(shape=(len(use_cases_names), len(bug_reports_names)), dtype='int64'))\n",
    "        \n",
    "        self.trace_links_df = pd.DataFrame(index = use_cases_names, \n",
    "                                       columns = bug_reports_names,\n",
    "                                       data = self._sim_matrix)\n",
    "        \n",
    "        for br_id, doc_query in zip(bug_reports_names, query):\n",
    "            for uc_id, doc_corpus in zip(use_cases_names, corpus):\n",
    "                self._sim_matrix.at[uc_id, br_id] = nltk.edit_distance(doc_corpus, doc_query)\n",
    "\n",
    "        for col in self.trace_links_df.columns:\n",
    "            self.trace_links_df[col] = [1 if x >= self.sim_measure_min_threshold[1] else 0 for x in self.trace_links_df[col]]\n",
    "    \n",
    "    def model_setup(self):\n",
    "        return {\"Setup\" : \n",
    "                  [\n",
    "                      {\"Name\" : self.name},\n",
    "                      {\"Similarity Measure and Minimum Threshold\" : self.sim_measure_min_threshold},\n",
    "                      {\"SVD Model\" : self.svd_model.get_params()},\n",
    "                      {\"Vectorizer\" : self.vectorizer.get_params()},\n",
    "                      {\"Vectorizer Type\" : type(self.vectorizer)}\n",
    "                  ]\n",
    "               }\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_query_vector(self):\n",
    "        return self._query_vector\n",
    "    \n",
    "    def get_svd_matrix(self):\n",
    "        return self._svd_matrix\n",
    "    \n",
    "    def get_sim_matrix(self):\n",
    "        return self._sim_matrix\n",
    "    \n",
    "    def get_sim_measure_min_threshold(self):\n",
    "        return self.sim_measure_min_threshold\n",
    "    \n",
    "    def get_trace_links_df(self):\n",
    "        return self.trace_links_df\n",
    "    \n",
    "    def get_vectorizer_type(self):\n",
    "        return type(self.vectorizer)\n",
    "    \n",
    "    def get_tokenizer_type(self):\n",
    "        return type(self.vectorizer.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, oracle, model):\n",
    "        self.model = model\n",
    "        self.oracle = oracle\n",
    "        self.recovered_links = model.trace_links_df\n",
    "        \n",
    "        self.eval_df = pd.DataFrame(columns=['precision','recall','fscore','support'])\n",
    "        self.mean_precision = -1\n",
    "        self.mean_recall = -1\n",
    "        self.mean_fscore = -1\n",
    "    \n",
    "    def evaluate_model(self, verbose=False, file=None):\n",
    "        y_true = csr_matrix(self.oracle.values, dtype=int)\n",
    "        y_pred = csr_matrix(self.recovered_links.values, dtype=int)\n",
    "        \n",
    "        p, r, f, sp = precision_recall_fscore_support(y_true, y_pred)\n",
    "\n",
    "        i = 0\n",
    "        for idx, row in self.oracle.iteritems():\n",
    "            self.eval_df.at[idx, 'precision'] = p[i]\n",
    "            self.eval_df.at[idx, 'recall'] = r[i]\n",
    "            self.eval_df.at[idx, 'fscore'] = f[i]\n",
    "            self.eval_df.at[idx, 'support'] = sp[i]\n",
    "            i += 1\n",
    "        \n",
    "        self.mean_precision = self.eval_df.precision.mean()\n",
    "        self.mean_recall = self.eval_df.recall.mean()\n",
    "        self.mean_fscore = self.eval_df.fscore.mean()\n",
    "        \n",
    "        if verbose:\n",
    "            self.print_report(file)\n",
    "    \n",
    "    def check_best_model(self, best_pre, best_rec, best_fs, best_md):\n",
    "        if best_rec <= self.get_mean_recall():\n",
    "            if best_pre <= self.get_mean_precision():\n",
    "                return (self.get_mean_precision(), self.get_mean_recall(), self.get_mean_fscore(), self.get_model())\n",
    "        return (best_pre, best_rec, best_fs, best_md)\n",
    "    \n",
    "    def print_report(self, file=None):\n",
    "        dic = self.model.model_setup()\n",
    "        dic['Measures'] = {}\n",
    "        dic['Measures']['Mean Precision of {}'.format(self.model.get_name())] = self.get_mean_precision()\n",
    "        dic['Measures']['Mean Recall of {}'.format(self.model.get_name())] = self.get_mean_recall()\n",
    "        dic['Measures']['Mean FScore of {}'.format(self.model.get_name())] = self.get_mean_fscore()\n",
    "        \n",
    "        if file is None:    \n",
    "            pprint.pprint(dic)\n",
    "        else:\n",
    "            file.write(pprint.pformat(dic))\n",
    "        \n",
    "    def plot_precision_vs_recall(self):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.plot(self.eval_df.recall, self.eval_df.precision, 'ro', label='Precision vs Recall')\n",
    "\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlabel('Recall')\n",
    "\n",
    "        plt.axis([0, 1.1, 0, 1.1])\n",
    "        plt.title(\"Precision vs Recall Plot - \" + self.model.get_name())\n",
    "        plt.show()\n",
    "    \n",
    "    def save_log(self):\n",
    "        print(\"\\nSaving model log...\")\n",
    "        with open('../logs/' + str(datetime.datetime.now()) + '.txt', 'a') as f:\n",
    "            evaluator.evaluate_model(verbose=True, file=f)\n",
    "        print(\"Model log saved with success!\")\n",
    "            \n",
    "    def get_mean_precision(self):\n",
    "        return self.mean_precision\n",
    "    \n",
    "    def get_mean_recall(self):\n",
    "        return self.mean_recall\n",
    "    \n",
    "    def get_mean_fscore(self):\n",
    "        return self.mean_fscore\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Recovering Efficiency\n",
    "\n",
    "In order to evaluate the efficiency of the algorithm tested (LSI), we use common metrics applied in the field of IR:\n",
    "\n",
    "    * Precision\n",
    "    * Recall\n",
    "    * F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis with Default Values of LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Measures': {'Mean FScore of LSI': 0.5714285714285714,\n",
      "              'Mean Precision of LSI': 0.6428571428571429,\n",
      "              'Mean Recall of LSI': 0.5357142857142857},\n",
      " 'Setup': [{'Name': 'LSI'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('cosine', 0.8)},\n",
      "           {'SVD Model': {'algorithm': 'randomized',\n",
      "                          'n_components': 100,\n",
      "                          'n_iter': 10,\n",
      "                          'random_state': 42,\n",
      "                          'tol': 0.0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.int64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 1),\n",
      "                           'norm': 'l2',\n",
      "                           'preprocessor': None,\n",
      "                           'smooth_idf': True,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'sublinear_tf': False,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': None,\n",
      "                           'use_idf': True,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>}]}\n"
     ]
    }
   ],
   "source": [
    "best_model = LSI()\n",
    "best_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "evaluator = ModelEvaluator(orc.oracle, best_model)\n",
    "evaluator.evaluate_model(verbose=True)\n",
    "#evaluator.plot_precision_vs_recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def generate_params_comb_list(**kwargs):\n",
    "    list_params = []\n",
    "    for key, values in kwargs.items():\n",
    "        aux_list = []\n",
    "        for v in values:\n",
    "            aux_list.append((key, v))\n",
    "        list_params.append(aux_list)\n",
    "    \n",
    "    list_tuples = list(product(*list_params))\n",
    "    \n",
    "    list_dicts = []\n",
    "    for ex_tup in list_tuples:\n",
    "        dic = {}\n",
    "        for in_tup in ex_tup:\n",
    "            dic[in_tup[0]] = in_tup[1]\n",
    "        list_dicts.append(dic)\n",
    "        \n",
    "    return list_dicts\n",
    "\n",
    "\n",
    "def plot_heatmap(results_df):\n",
    "    tmp_df = pd.DataFrame({'precision': results_df['precision'], \n",
    "                           'recall' : results_df['recall'], \n",
    "                           'fscore': results_df['fscore'], \n",
    "                           'model': results_df['model']})\n",
    "    tmp_df.set_index('model', inplace=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 4 * 100)) \n",
    "    ax = sns.heatmap(tmp_df, vmin=0, vmax=1, linewidths=.5, cmap=\"Greens\", annot=True, cbar=False, ax=ax)\n",
    "\n",
    "\n",
    "def highlight_df(df):\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    return df.style.background_gradient(cmap=cm)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Test Jaccard Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "------------ Report -------------------\n",
      "\n",
      "Total of Analyzed Hyperparameters Combinations: 1\n",
      "\n",
      "Best Model and Hyperparameters Found: LSI_Model_0\n",
      "\n",
      "{'Measures': {'Mean FScore of LSI_Model_0': 0.0,\n",
      "              'Mean Precision of LSI_Model_0': 0.0,\n",
      "              'Mean Recall of LSI_Model_0': 0.0},\n",
      " 'Setup': [{'Name': 'LSI_Model_0'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('jaccard', 0.8)},\n",
      "           {'SVD Model': {'algorithm': 'randomized',\n",
      "                          'n_components': 100,\n",
      "                          'n_iter': 10,\n",
      "                          'random_state': 42,\n",
      "                          'tol': 0.0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.int64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 1),\n",
      "                           'norm': 'l2',\n",
      "                           'preprocessor': None,\n",
      "                           'smooth_idf': True,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'sublinear_tf': False,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': <__main__.PorterStemmerBased_Tokenizer object at 0x7efd4498af98>,\n",
      "                           'use_idf': True,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>}]}\n"
     ]
    }
   ],
   "source": [
    "all_hyperparams = {\n",
    "    LSI_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [(1,1)],\n",
    "    LSI_Model_Hyperp.VECTORIZER.value : [TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)],\n",
    "    LSI_Model_Hyperp.VECTORIZER_TOKENIZER.value : [PorterStemmerBased_Tokenizer()],\n",
    "    LSI_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('jaccard',x) for x in [.8]],\n",
    "}\n",
    "\n",
    "hyperparams = generate_params_comb_list(**all_hyperparams)\n",
    "\n",
    "print('Performing model optimizations...')\n",
    "best_precision = -1\n",
    "best_recall = -1\n",
    "best_fscore = -1\n",
    "best_model = None\n",
    "\n",
    "results = {'precision': [], 'recall': [], 'fscore': [], 'model': []}\n",
    "\n",
    "i = 0\n",
    "for hyperp in hyperparams:\n",
    "    hyperp[LSI_Model_Hyperp.NAME.value] = 'LSI_Model_{}'.format(i)\n",
    "    current_model = LSI(**hyperp)\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "\n",
    "    if best_recall <= evaluator.get_mean_recall():\n",
    "        if best_precision <= evaluator.get_mean_precision():\n",
    "            best_recall = evaluator.get_mean_recall()\n",
    "            best_precision = evaluator.get_mean_precision()\n",
    "            best_fscore = evaluator.get_mean_fscore()\n",
    "            best_model = current_model\n",
    "    \n",
    "    results['precision'].append(evaluator.get_mean_precision())\n",
    "    results['recall'].append(evaluator.get_mean_recall())\n",
    "    results['fscore'].append(evaluator.get_mean_fscore())\n",
    "    results['model'].append(current_model.get_name())\n",
    "    \n",
    "    i += 1 \n",
    "    \n",
    "print(\"------------ Report -------------------\\n\")\n",
    "print(\"Total of Analyzed Hyperparameters Combinations: {}\".format(len(hyperparams)))\n",
    "\n",
    "print(\"\\nBest Model and Hyperparameters Found: {}\\n\".format(best_model.get_name()))            \n",
    "evaluator = ModelEvaluator(orc.oracle, best_model)\n",
    "evaluator.evaluate_model(verbose=True)\n",
    "\n",
    "#print(\"\\nHeatmap of All Models\")\n",
    "#plot_heatmap(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find The Best Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_hyperparams = {\n",
    "    LSI_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('cosine' ,x)  for x in [.75,.85,.95]] +\n",
    "                                                       [('jaccard',x)  for x in [.55,.75,.90]],\n",
    "                                                       #[('edit',x)    for x in [.55,.75,.90]],\n",
    "    LSI_Model_Hyperp.SVD_MODEL_N_COMPONENTS.value: [5,10,20,50,90],\n",
    "    LSI_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [(1,1), (1,2)],\n",
    "    LSI_Model_Hyperp.VECTORIZER.value : [TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True), \n",
    "                         CountVectorizer(stop_words='english')],\n",
    "    LSI_Model_Hyperp.VECTORIZER_TOKENIZER.value : [PorterStemmerBased_Tokenizer(), LancasterStemmerBased_Tokenizer(), \n",
    "                                                   WordNetBased_LemmaTokenizer(), SnowballStemmerBased_Tokenizer()]\n",
    "}\n",
    "\n",
    "hyperparams = generate_params_comb_list(**all_hyperparams)          \n",
    "\n",
    "print('Performing model hyperparameters search...')\n",
    "best_precision = -1\n",
    "best_recall = -1\n",
    "best_fscore = -1\n",
    "best_model = None\n",
    "\n",
    "results = pd.DataFrame(columns=['precision', 'recall', 'fscore', 'model', 'vectorizer',\n",
    "                                'tokenizer', 'metric', 'metric_value'])\n",
    "\n",
    "for idx, hyperp in enumerate(hyperparams):\n",
    "    current_model = LSI(**hyperp)\n",
    "    current_model.set_name('LSI_Model_{}'.format(idx))\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    \n",
    "    best_precision, best_recall, best_fscore, best_model = evaluator.check_best_model(best_precision, best_recall, best_fscore, best_model)\n",
    "    \n",
    "    results = results.append(pd.DataFrame([[evaluator.get_mean_precision(), \n",
    "                    evaluator.get_mean_recall(),\n",
    "                    evaluator.get_mean_fscore(), \n",
    "                    evaluator.get_model().get_name(),\n",
    "                    evaluator.get_model().get_vectorizer_type(), \n",
    "                    evaluator.get_model().get_tokenizer_type(),\n",
    "                    evaluator.get_model().get_sim_measure_min_threshold()[0],\n",
    "                    evaluator.get_model().get_sim_measure_min_threshold()[1]]], columns=results.columns.tolist()), ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"------------ Report -------------------\\n\")\n",
    "print(\"Total of Analyzed Hyperparameters Combinations: {}\".format(len(hyperparams)))\n",
    "\n",
    "print(\"\\nBest Model and Hyperparameters Found: {}\\n\".format(best_model.get_name()))            \n",
    "evaluator = ModelEvaluator(orc.oracle, best_model)\n",
    "evaluator.evaluate_model(verbose=True)\n",
    "\n",
    "#print(\"\\nPlot Precision vs Recall - Best Model\")\n",
    "#evaluator.plot_precision_vs_recall()\n",
    "\n",
    "print(\"\\nHeatmap of All Models\")\n",
    "plot_heatmap(results)\n",
    "\n",
    "#evaluator.save_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model hyperparameters search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467857</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>LSI_Model_0</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555102</td>\n",
       "      <td>LSI_Model_1</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.473810</td>\n",
       "      <td>LSI_Model_2</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>LSI_Model_3</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.300170</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.427551</td>\n",
       "      <td>LSI_Model_4</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.288776</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.419218</td>\n",
       "      <td>LSI_Model_5</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.427891</td>\n",
       "      <td>LSI_Model_6</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.312585</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>LSI_Model_7</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.550340</td>\n",
       "      <td>LSI_Model_8</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>LSI_Model_9</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>LSI_Model_10</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>LSI_Model_11</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.285544</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.410884</td>\n",
       "      <td>LSI_Model_12</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.282143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.407823</td>\n",
       "      <td>LSI_Model_13</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.422619</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.475510</td>\n",
       "      <td>LSI_Model_14</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.296259</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.423129</td>\n",
       "      <td>LSI_Model_15</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>LSI_Model_16</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.545238</td>\n",
       "      <td>LSI_Model_17</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>LSI_Model_18</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>LSI_Model_19</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>LSI_Model_20</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>LSI_Model_21</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>LSI_Model_22</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>LSI_Model_23</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>LSI_Model_24</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>LSI_Model_25</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>LSI_Model_26</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>LSI_Model_27</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>LSI_Model_28</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>LSI_Model_29</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_450</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_451</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_452</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_453</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_454</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_455</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_456</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_457</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_458</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_459</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_460</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_461</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_462</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_463</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_464</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_465</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_466</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_467</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_468</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_469</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_470</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_471</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_472</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_473</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_474</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_475</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.TfidfV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_476</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.PorterStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_477</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.LancasterStemmerBased_Tokeniz...</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>LSI_Model_478</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.WordNetBased_LemmaTokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LSI_Model_479</td>\n",
       "      <td>&lt;class 'sklearn.feature_extraction.text.CountV...</td>\n",
       "      <td>&lt;class '__main__.SnowballStemmerBased_Tokenizer'&gt;</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precision    recall    fscore          model  \\\n",
       "0     0.467857  0.928571  0.591667    LSI_Model_0   \n",
       "1     0.446429  0.833333  0.555102    LSI_Model_1   \n",
       "2     0.380952  0.714286  0.473810    LSI_Model_2   \n",
       "3     0.425000  0.857143  0.538095    LSI_Model_3   \n",
       "4     0.300170  0.857143  0.427551    LSI_Model_4   \n",
       "5     0.288776  0.857143  0.419218    LSI_Model_5   \n",
       "6     0.386905  0.500000  0.427891    LSI_Model_6   \n",
       "7     0.312585  0.857143  0.443367    LSI_Model_7   \n",
       "8     0.442857  0.833333  0.550340    LSI_Model_8   \n",
       "9     0.416667  0.738095  0.509524    LSI_Model_9   \n",
       "10    0.392857  0.714286  0.485714   LSI_Model_10   \n",
       "11    0.410714  0.785714  0.514286   LSI_Model_11   \n",
       "12    0.285544  0.857143  0.410884   LSI_Model_12   \n",
       "13    0.282143  0.821429  0.407823   LSI_Model_13   \n",
       "14    0.422619  0.571429  0.475510   LSI_Model_14   \n",
       "15    0.296259  0.857143  0.423129   LSI_Model_15   \n",
       "16    0.583333  0.630952  0.585714   LSI_Model_16   \n",
       "17    0.547619  0.595238  0.545238   LSI_Model_17   \n",
       "18    0.500000  0.571429  0.523810   LSI_Model_18   \n",
       "19    0.547619  0.607143  0.557143   LSI_Model_19   \n",
       "20    0.488095  0.595238  0.523810   LSI_Model_20   \n",
       "21    0.511905  0.666667  0.561905   LSI_Model_21   \n",
       "22    0.392857  0.428571  0.404762   LSI_Model_22   \n",
       "23    0.488095  0.595238  0.523810   LSI_Model_23   \n",
       "24    0.500000  0.571429  0.523810   LSI_Model_24   \n",
       "25    0.476190  0.571429  0.509524   LSI_Model_25   \n",
       "26    0.500000  0.571429  0.523810   LSI_Model_26   \n",
       "27    0.500000  0.571429  0.523810   LSI_Model_27   \n",
       "28    0.511905  0.595238  0.538095   LSI_Model_28   \n",
       "29    0.500000  0.666667  0.550000   LSI_Model_29   \n",
       "..         ...       ...       ...            ...   \n",
       "450   0.025000  0.142857  0.041558  LSI_Model_450   \n",
       "451   0.000000  0.000000  0.000000  LSI_Model_451   \n",
       "452   0.000000  0.000000  0.000000  LSI_Model_452   \n",
       "453   0.000000  0.000000  0.000000  LSI_Model_453   \n",
       "454   0.025000  0.142857  0.041558  LSI_Model_454   \n",
       "455   0.000000  0.000000  0.000000  LSI_Model_455   \n",
       "456   0.000000  0.000000  0.000000  LSI_Model_456   \n",
       "457   0.000000  0.000000  0.000000  LSI_Model_457   \n",
       "458   0.025000  0.142857  0.041558  LSI_Model_458   \n",
       "459   0.000000  0.000000  0.000000  LSI_Model_459   \n",
       "460   0.000000  0.000000  0.000000  LSI_Model_460   \n",
       "461   0.000000  0.000000  0.000000  LSI_Model_461   \n",
       "462   0.025000  0.142857  0.041558  LSI_Model_462   \n",
       "463   0.000000  0.000000  0.000000  LSI_Model_463   \n",
       "464   0.000000  0.000000  0.000000  LSI_Model_464   \n",
       "465   0.000000  0.000000  0.000000  LSI_Model_465   \n",
       "466   0.025000  0.142857  0.041558  LSI_Model_466   \n",
       "467   0.000000  0.000000  0.000000  LSI_Model_467   \n",
       "468   0.000000  0.000000  0.000000  LSI_Model_468   \n",
       "469   0.000000  0.000000  0.000000  LSI_Model_469   \n",
       "470   0.025000  0.142857  0.041558  LSI_Model_470   \n",
       "471   0.000000  0.000000  0.000000  LSI_Model_471   \n",
       "472   0.000000  0.000000  0.000000  LSI_Model_472   \n",
       "473   0.000000  0.000000  0.000000  LSI_Model_473   \n",
       "474   0.025000  0.142857  0.041558  LSI_Model_474   \n",
       "475   0.000000  0.000000  0.000000  LSI_Model_475   \n",
       "476   0.000000  0.000000  0.000000  LSI_Model_476   \n",
       "477   0.000000  0.000000  0.000000  LSI_Model_477   \n",
       "478   0.025000  0.142857  0.041558  LSI_Model_478   \n",
       "479   0.000000  0.000000  0.000000  LSI_Model_479   \n",
       "\n",
       "                                            vectorizer  \\\n",
       "0    <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "1    <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "2    <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "3    <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "4    <class 'sklearn.feature_extraction.text.CountV...   \n",
       "5    <class 'sklearn.feature_extraction.text.CountV...   \n",
       "6    <class 'sklearn.feature_extraction.text.CountV...   \n",
       "7    <class 'sklearn.feature_extraction.text.CountV...   \n",
       "8    <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "9    <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "10   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "11   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "12   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "13   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "14   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "15   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "16   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "17   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "18   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "19   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "20   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "21   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "22   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "23   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "24   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "25   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "26   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "27   <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "28   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "29   <class 'sklearn.feature_extraction.text.CountV...   \n",
       "..                                                 ...   \n",
       "450  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "451  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "452  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "453  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "454  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "455  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "456  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "457  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "458  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "459  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "460  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "461  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "462  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "463  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "464  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "465  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "466  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "467  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "468  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "469  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "470  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "471  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "472  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "473  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "474  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "475  <class 'sklearn.feature_extraction.text.TfidfV...   \n",
       "476  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "477  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "478  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "479  <class 'sklearn.feature_extraction.text.CountV...   \n",
       "\n",
       "                                             tokenizer   metric  metric_value  \n",
       "0      <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "1    <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "2       <class '__main__.WordNetBased_LemmaTokenizer'>   cosine          0.75  \n",
       "3    <class '__main__.SnowballStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "4      <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "5    <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "6       <class '__main__.WordNetBased_LemmaTokenizer'>   cosine          0.75  \n",
       "7    <class '__main__.SnowballStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "8      <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "9    <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "10      <class '__main__.WordNetBased_LemmaTokenizer'>   cosine          0.75  \n",
       "11   <class '__main__.SnowballStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "12     <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "13   <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "14      <class '__main__.WordNetBased_LemmaTokenizer'>   cosine          0.75  \n",
       "15   <class '__main__.SnowballStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "16     <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "17   <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "18      <class '__main__.WordNetBased_LemmaTokenizer'>   cosine          0.75  \n",
       "19   <class '__main__.SnowballStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "20     <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "21   <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "22      <class '__main__.WordNetBased_LemmaTokenizer'>   cosine          0.75  \n",
       "23   <class '__main__.SnowballStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "24     <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "25   <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "26      <class '__main__.WordNetBased_LemmaTokenizer'>   cosine          0.75  \n",
       "27   <class '__main__.SnowballStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "28     <class '__main__.PorterStemmerBased_Tokenizer'>   cosine          0.75  \n",
       "29   <class '__main__.LancasterStemmerBased_Tokeniz...   cosine          0.75  \n",
       "..                                                 ...      ...           ...  \n",
       "450     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "451  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "452    <class '__main__.PorterStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "453  <class '__main__.LancasterStemmerBased_Tokeniz...  jaccard          0.90  \n",
       "454     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "455  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "456    <class '__main__.PorterStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "457  <class '__main__.LancasterStemmerBased_Tokeniz...  jaccard          0.90  \n",
       "458     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "459  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "460    <class '__main__.PorterStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "461  <class '__main__.LancasterStemmerBased_Tokeniz...  jaccard          0.90  \n",
       "462     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "463  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "464    <class '__main__.PorterStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "465  <class '__main__.LancasterStemmerBased_Tokeniz...  jaccard          0.90  \n",
       "466     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "467  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "468    <class '__main__.PorterStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "469  <class '__main__.LancasterStemmerBased_Tokeniz...  jaccard          0.90  \n",
       "470     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "471  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "472    <class '__main__.PorterStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "473  <class '__main__.LancasterStemmerBased_Tokeniz...  jaccard          0.90  \n",
       "474     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "475  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "476    <class '__main__.PorterStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "477  <class '__main__.LancasterStemmerBased_Tokeniz...  jaccard          0.90  \n",
       "478     <class '__main__.WordNetBased_LemmaTokenizer'>  jaccard          0.90  \n",
       "479  <class '__main__.SnowballStemmerBased_Tokenizer'>  jaccard          0.90  \n",
       "\n",
       "[480 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hyperparams = {\n",
    "    LSI_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('cosine' ,x)  for x in [.75,.85,.95]] +\n",
    "                                                       [('jaccard',x)  for x in [.55,.75,.90]],\n",
    "                                                       #[('edit',x)    for x in [.55,.75,.90]],\n",
    "    LSI_Model_Hyperp.SVD_MODEL_N_COMPONENTS.value: [5,10,20,50,90],\n",
    "    LSI_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [(1,1), (1,2)],\n",
    "    LSI_Model_Hyperp.VECTORIZER.value : [TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True), \n",
    "                         CountVectorizer(stop_words='english')],\n",
    "    LSI_Model_Hyperp.VECTORIZER_TOKENIZER.value : [PorterStemmerBased_Tokenizer(), LancasterStemmerBased_Tokenizer(), \n",
    "                                                   WordNetBased_LemmaTokenizer(), SnowballStemmerBased_Tokenizer()]\n",
    "}\n",
    "\n",
    "hyperparams = generate_params_comb_list(**all_hyperparams)          \n",
    "\n",
    "print('Performing model hyperparameters search...')\n",
    "best_precision = -1\n",
    "best_recall = -1\n",
    "best_fscore = -1\n",
    "best_model = None\n",
    "\n",
    "def run_model(idx, **hyperp):    \n",
    "    current_model = LSI(**hyperp)\n",
    "    current_model.set_name('LSI_Model_{}'.format(idx))\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    \n",
    "    return([evaluator.get_mean_precision(), \n",
    "                    evaluator.get_mean_recall(),\n",
    "                    evaluator.get_mean_fscore(), \n",
    "                    evaluator.get_model().get_name(),\n",
    "                    evaluator.get_model().get_vectorizer_type(), \n",
    "                    evaluator.get_model().get_tokenizer_type(),\n",
    "                    evaluator.get_model().get_sim_measure_min_threshold()[0],\n",
    "                    evaluator.get_model().get_sim_measure_min_threshold()[1]])\n",
    "\n",
    "tasks = [(idx,hp) for idx,hp in enumerate(hyperparams)]\n",
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(run_model)(idx, **hp) for idx,hp in tasks)\n",
    "results_df = pd.DataFrame(results, columns=['precision', 'recall', 'fscore', 'model', 'vectorizer', 'tokenizer', 'metric', 'metric_value'])\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor idx, hyperp in enumerate(hyperparams):\\n    current_model = LSI(**hyperp)\\n    current_model.set_name(\\'LSI_Model_{}\\'.format(idx))\\n    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\\n    \\n    evaluator = ModelEvaluator(orc.oracle, current_model)\\n    evaluator.evaluate_model()\\n    \\n    best_precision, best_recall, best_fscore, best_model = evaluator.check_best_model(best_precision, best_recall, best_fscore, best_model)\\n    \\n    results = results.append(pd.DataFrame([], columns=results.columns.tolist()), ignore_index=True)\\n\\n\\nprint(\"------------ Report -------------------\\n\")\\nprint(\"Total of Analyzed Hyperparameters Combinations: {}\".format(len(hyperparams)))\\n\\nprint(\"\\nBest Model and Hyperparameters Found: {}\\n\".format(best_model.get_name()))            \\nevaluator = ModelEvaluator(orc.oracle, best_model)\\nevaluator.evaluate_model(verbose=True)\\n\\n#print(\"\\nPlot Precision vs Recall - Best Model\")\\n#evaluator.plot_precision_vs_recall()\\n\\nprint(\"\\nHeatmap of All Models\")\\nplot_heatmap(results)\\n\\n#evaluator.save_log()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for idx, hyperp in enumerate(hyperparams):\n",
    "    current_model = LSI(**hyperp)\n",
    "    current_model.set_name('LSI_Model_{}'.format(idx))\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    \n",
    "    best_precision, best_recall, best_fscore, best_model = evaluator.check_best_model(best_precision, best_recall, best_fscore, best_model)\n",
    "    \n",
    "    results = results.append(pd.DataFrame([], columns=results.columns.tolist()), ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"------------ Report -------------------\\n\")\n",
    "print(\"Total of Analyzed Hyperparameters Combinations: {}\".format(len(hyperparams)))\n",
    "\n",
    "print(\"\\nBest Model and Hyperparameters Found: {}\\n\".format(best_model.get_name()))            \n",
    "evaluator = ModelEvaluator(orc.oracle, best_model)\n",
    "evaluator.evaluate_model(verbose=True)\n",
    "\n",
    "#print(\"\\nPlot Precision vs Recall - Best Model\")\n",
    "#evaluator.plot_precision_vs_recall()\n",
    "\n",
    "print(\"\\nHeatmap of All Models\")\n",
    "plot_heatmap(results)\n",
    "\n",
    "#evaluator.save_log()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_trace_links_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c9c519da0a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhighlight_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace_links_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_trace_links_df'"
     ]
    }
   ],
   "source": [
    "highlight_df(best_model.get_trace_links_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_df(orc.oracle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_hyperparams_2 = {\n",
    "    LSI_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('cosine', x) for x in np.arange(1,100, .1)],\n",
    "    LSI_Model_Hyperp.SVD_MODEL_N_COMPONENTS.value: [best_model.svd_model.n_components],\n",
    "    LSI_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [best_model.vectorizer.ngram_range],\n",
    "    LSI_Model_Hyperp.VECTORIZER.value : [best_model.vectorizer],\n",
    "    LSI_Model_Hyperp.VECTORIZER_TOKENIZER.value : [best_model.vectorizer.tokenizer]\n",
    "}\n",
    "\n",
    "hyperparams = generate_params_comb_list(**all_hyperparams)\n",
    "\n",
    "dic = {'precision':[], 'recall':[], 'threshold':[]}\n",
    "\n",
    "for hyperp in hyperparams:\n",
    "    current_model = LSI(**hyperp)\n",
    "    current_model.recover_links(corpus, query, use_cases_names, bug_reports_names)\n",
    "    \n",
    "    evaluator = ModelEvaluator(orc.oracle, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    \n",
    "    dic['precision'].append(evaluator.get_mean_precision())\n",
    "    dic['recall'].append(evaluator.get_mean_recall())\n",
    "    dic['threshold'].append(current_model.get_sim_measure_min_threshold()[1])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(dic)\n",
    "\n",
    "plt.plot(df['threshold'], df['precision'], 'r-')\n",
    "plt.plot(df['threshold'], df['recall'], 'b-')\n",
    "plt.xlabel('threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Checking Answer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sims_1 = pd.DataFrame(np.matrix(best_model.trace_links_df))\n",
    "sims_2 = pd.DataFrame(np.matrix(pairwise.cosine_similarity(best_model.get_svd_matrix(), best_model.get_query_vector()) ))\n",
    "\n",
    "for col in sims_2.columns:\n",
    "    sims_2[col] = [1 if x >= best_model.get_sim_measure_min_threshold()[1] else 0 for x in sims_2[col]]\n",
    "\n",
    "sims_1.equals(sims_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
